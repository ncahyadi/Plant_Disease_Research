{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "55f68b2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.datasets import mnist\n",
    "\n",
    "import autokeras as ak\n",
    "\n",
    "from datetime import datetime, timedelta\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "76e19a4a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Setting up data generator...\n",
      "Found 8431 files belonging to 5 classes.\n",
      "Found 1052 files belonging to 5 classes.\n",
      "Found 1060 files belonging to 5 classes.\n"
     ]
    }
   ],
   "source": [
    "print('Setting up data generator...')\n",
    "train_dir = '../../data_v1_adjusted/train'\n",
    "valid_dir = '../../data_v1_adjusted/val'\n",
    "test_dir = '../../data_v1_adjusted/test'\n",
    "\n",
    "BATCH_SIZE = 64\n",
    "IMG_SIZE = (224, 224)\n",
    "IMG_SHAPE = IMG_SIZE + (3,)\n",
    "base_learning_rate = 0.0003\n",
    "initial_epochs = 1\n",
    "fine_tune_epochs = 1\n",
    "pred_thresholds = 0.4, 0.5, 0.6, 0.7, 0.8, 0.9\n",
    "fine_tune_at = 100\n",
    "drop_out = 0.8\n",
    "\n",
    "train_dataset = tf.keras.utils.image_dataset_from_directory(train_dir,\n",
    "                                                            shuffle=True,\n",
    "                                                            batch_size=BATCH_SIZE,\n",
    "                                                            image_size=IMG_SIZE)\n",
    "train_labels = tf.concat([y for x, y in train_dataset], axis=0)\n",
    "\n",
    "validation_dataset = tf.keras.utils.image_dataset_from_directory(valid_dir,\n",
    "                                                                 shuffle=True,\n",
    "                                                                 batch_size=BATCH_SIZE,\n",
    "                                                                 image_size=IMG_SIZE)\n",
    "valid_labels = tf.concat([y for x, y in validation_dataset], axis=0)\n",
    "\n",
    "test_dataset = tf.keras.utils.image_dataset_from_directory(test_dir,\n",
    "                                                           batch_size=BATCH_SIZE,\n",
    "                                                           image_size=IMG_SIZE)\n",
    "test_labels = tf.concat([y for x, y in test_dataset], axis=0)\n",
    "\n",
    "classes = train_dataset.class_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5e03372e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "configuring data training performance...\n"
     ]
    }
   ],
   "source": [
    "print('configuring data training performance...')\n",
    "AUTOTUNE = tf.data.AUTOTUNE\n",
    "\n",
    "train_dataset = train_dataset.prefetch(buffer_size=AUTOTUNE)\n",
    "validation_dataset = validation_dataset.prefetch(buffer_size=AUTOTUNE)\n",
    "test_dataset = test_dataset.prefetch(buffer_size=AUTOTUNE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "14011a9b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 10 Complete [00h 07m 29s]\n",
      "val_loss: 1.565567970275879\n",
      "\n",
      "Best val_loss So Far: 1.565567970275879\n",
      "Total elapsed time: 03h 34m 38s\n",
      "INFO:tensorflow:Oracle triggered exit\n",
      "Epoch 1/10\n",
      "132/132 [==============================] - 37s 258ms/step - loss: 1.5854 - accuracy: 0.2994 - val_loss: 1.6011 - val_accuracy: 0.3118\n",
      "Epoch 2/10\n",
      "132/132 [==============================] - 41s 291ms/step - loss: 1.5727 - accuracy: 0.3118 - val_loss: 1.5720 - val_accuracy: 0.3118\n",
      "Epoch 3/10\n",
      "132/132 [==============================] - 43s 306ms/step - loss: 1.5685 - accuracy: 0.3117 - val_loss: 1.5668 - val_accuracy: 0.3118\n",
      "Epoch 4/10\n",
      "132/132 [==============================] - 43s 301ms/step - loss: 1.5690 - accuracy: 0.3117 - val_loss: 1.5678 - val_accuracy: 0.3118\n",
      "Epoch 5/10\n",
      "132/132 [==============================] - 44s 315ms/step - loss: 1.5683 - accuracy: 0.3117 - val_loss: 1.5665 - val_accuracy: 0.3118\n",
      "Epoch 6/10\n",
      "132/132 [==============================] - 45s 320ms/step - loss: 1.5677 - accuracy: 0.3117 - val_loss: 1.5658 - val_accuracy: 0.3118\n",
      "Epoch 7/10\n",
      "132/132 [==============================] - 45s 318ms/step - loss: 1.5675 - accuracy: 0.3117 - val_loss: 1.5661 - val_accuracy: 0.3118\n",
      "Epoch 8/10\n",
      "132/132 [==============================] - 43s 306ms/step - loss: 1.5670 - accuracy: 0.3117 - val_loss: 1.5663 - val_accuracy: 0.3118\n",
      "Epoch 9/10\n",
      "132/132 [==============================] - 46s 329ms/step - loss: 1.5665 - accuracy: 0.3117 - val_loss: 1.5667 - val_accuracy: 0.3118\n",
      "Epoch 10/10\n",
      "132/132 [==============================] - 44s 314ms/step - loss: 1.5666 - accuracy: 0.3117 - val_loss: 1.5660 - val_accuracy: 0.3118\n",
      "INFO:tensorflow:Assets written to: .\\auto_model\\best_model\\assets\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x2011d2652c8>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_node = ak.ImageInput()\n",
    "output_node = ak.ImageBlock(\n",
    "    block_type=None,\n",
    "    # Normalize the dataset.\n",
    "    normalize=True,\n",
    "    # Do not do data augmentation.\n",
    "    augment=True,\n",
    ")(input_node)\n",
    "output_node = ak.ClassificationHead(len(classes), loss=tf.keras.losses.CategoricalCrossentropy())(output_node)\n",
    "clf = ak.AutoModel(\n",
    "    inputs=input_node, outputs=output_node, overwrite=False, max_trials=10\n",
    ")\n",
    "clf.fit(train_dataset, validation_data=validation_dataset, epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "990f710d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_1 (InputLayer)        [(None, 224, 224, 3)]     0         \n",
      "                                                                 \n",
      " cast_to_float32 (CastToFloa  (None, 224, 224, 3)      0         \n",
      " t32)                                                            \n",
      "                                                                 \n",
      " normalization (Normalizatio  (None, 224, 224, 3)      7         \n",
      " n)                                                              \n",
      "                                                                 \n",
      " random_flip (RandomFlip)    (None, 224, 224, 3)       0         \n",
      "                                                                 \n",
      " conv2d (Conv2D)             (None, 222, 222, 32)      896       \n",
      "                                                                 \n",
      " conv2d_1 (Conv2D)           (None, 220, 220, 32)      9248      \n",
      "                                                                 \n",
      " max_pooling2d (MaxPooling2D  (None, 110, 110, 32)     0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " conv2d_2 (Conv2D)           (None, 108, 108, 32)      9248      \n",
      "                                                                 \n",
      " conv2d_3 (Conv2D)           (None, 106, 106, 32)      9248      \n",
      "                                                                 \n",
      " max_pooling2d_1 (MaxPooling  (None, 53, 53, 32)       0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 89888)             0         \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 89888)             0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 5)                 449445    \n",
      "                                                                 \n",
      " classification_head_1 (Soft  (None, 5)                0         \n",
      " max)                                                            \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 478,092\n",
      "Trainable params: 478,085\n",
      "Non-trainable params: 7\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model_res = clf.export_model()\n",
    "model_res.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d35fcd1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "labAI1",
   "language": "python",
   "name": "labai1"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
